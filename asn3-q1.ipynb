{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "In this question we will:\n",
    "\n",
    "- Design and implement a feature that can be used to creates a feature map sensitive to \"greenness\".\n",
    "- Utilize thresholding techniques of this \"greenness\" feature to obtain a segmentation of green leaves in images with a cluttered background.\n",
    "- Implement evaluation metrics to measure the quality of a segmentation produced by the thresholding\n",
    "- Use the metrics to evaluate the segmentation algoirthm's perormance on a dataset of images of green leaves on a cluttered background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Write your Segmentation Algoirthm\n",
    "\n",
    "Write a function that segments a leaf image, and returns a binary (`dtype='bool'`) image representing the segmentation.  Your algorithm must be based on thresholding.  Determine a metric that can be used to meaure the \"greenness\" of the colour of a given pixel.  Your algoirthm should create a \"feature map\" by computing this feature for each pixel, thus creating an \"image\" where each pixel's \"intensity\" is the value of the \"greenness\" feature.   Then use a thresholding method of your choice to segment the image's green regions.    You should also consider whether doing some region processing after segmentation can improve the results.  This function should return the segmenetion of the image as a binary image with a single connected component since you can take advantage of the fact that each image is known to contain only a single leaf.\n",
    "\n",
    "_Hint: You'll need to be a bit creative when devising your solution -- no single technique from class is likely to give you a particularly good solution, and you may need to think of some tricks that were not explicitly covered in class.  However, you can get a good result with a fairly simple algorithm.  You'll also need to decide how to handle the fact that the input images are colour, although this shouldn't pose too much of a problem, in fact, it is an advantage!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.util as util\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "import os as os\n",
    "\n",
    "# You can import other modules as needed.\n",
    "\n",
    "def segleaf(I):\n",
    "    '''\n",
    "    Segment a leaf image.\n",
    "    :param I: Color leaf image to segment.\n",
    "    :return: Logical image where True pixels represent foreground (i.e. leaf pixels).\n",
    "    '''\n",
    " \n",
    "    pass   # replace this with your return statement.  This is just a placeholder to prevent a syntax error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Implement Segmentation Performace Measures\n",
    "\n",
    "Write functions to compute the Mean Squared Distance (MSD), Hausdorff Distance (HD) and Dice Similarity Coefficient (DSC) measures of segmentation quality.  \n",
    "\n",
    "For MSD and HD, I suggest you reprsent boundaries by N-row, 2-column arrays where each row is the coordinate of one pixel on the region's boundary of the form [r,c], row first, then column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Write a Validation driver program.\n",
    "\n",
    "Write code that segments each image (using the function in Step 1), and computes the MSD, HD, and DSC for each segmentation (using the functions in Step 2).  Print the MSD, HD, and DSC of each segmentation to the console as you perform it.  At the end, print the average and standard deviation of the DSC, the MSD, and the HD over all of the images.  Also print the percentage of regions that were \"recognized\" (see below).  Sample output is in the assignment description document.\n",
    "\n",
    "The general approach should be, for each input image:\n",
    "\n",
    "* load the image and it's ground truth (use the provided leaf image dataset, described in section 2.2. of the assignment PDF) -- a .csv file is provided with the names of all images so that you can process the files in the same manner as Assignment 1, question 1)\n",
    "* segment the input image using your function from Step 1\n",
    "* extract the region boundary points from the segmented image and ground truth image; store them in Nx2 arrays as described above (see lecture notes Topic 6, slide 68 for an example on how to do this).\n",
    "* Compute the MSD and the HD from the two sets of boundary points (using the appropriate functions in Step 2).\n",
    "* Compute the DSC from the segmented image and the ground truth image (using the appropriate function from Step 2).\n",
    "* Determine whether the leaf was \"recognized\" (a leaf is recognized if it's DSC is greater than 0.6).\n",
    "* Print the MSD, HD, and DSC to the console (see sample output).\n",
    "\n",
    "When finished processing each image, don't forget to print the average and standard deviation of the DSC for all images, and the percentage of images where the leaf was \"recognized\".\n",
    "\n",
    "_Feel free to define additional helper functions for your program if you think it will help._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#### Validate ####\n",
    "\n",
    "# Paths for folders -- original and ground truth images\n",
    "images_path = os.path.join('.', 'images')\n",
    "gt_path = os.path.join('.', 'groundtruth')\n",
    "\n",
    "# TODO Change the I/O to use a CSV file like in assignment 0.\n",
    "\n",
    "\n",
    "# Iterate over all files in the original images folder\n",
    "for root, dirs, files in os.walk(images_path):\n",
    "    for filename in files:\n",
    "        # ignore files that are not PNG files.\n",
    "        if filename[-4:] != '.png':\n",
    "            continue\n",
    "            \n",
    "        # concatenate variable root with filename to get the path to an input file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4:  Display Examples\n",
    "\n",
    "Choose one input image where your algoirthm performed very well.  Choose another image where the algorithm did not perform well.  Display the two original images with the segmentation superimposed on top (There is an example in the lecture notes -- last slide, Topic 6 -- showing how to do this).  Also display the same two image's ground truth with the segmentation superimposed on top.    Title the images to indicate which is the \"good\" example, and which is the \"bad\" example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: A time for reflection.\n",
    "\n",
    "### Answer the following questions right here in this block.\n",
    "\n",
    "1. In a few sentences, briefly explain what your segmentation algorithm from Step 1 does and how it works.  \n",
    "\n",
    "\t_Your answer:_  \n",
    "\n",
    "2. Consider your example \"good\" result.  What, if anything, about your algoirthm is preventing you from getting a better result with this image?  If you weren't able to get any results, leave this blank, or explain what was preventing you from getting a result.\n",
    "\n",
    "\t_Your answer:_  \n",
    "\n",
    "3. Consider your example \"bad\" result.  What is it about your algoirthm caused the poor performance?   If you weren't able to get any results, leave this blank.\n",
    "\n",
    "\t_Your answer:_  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
